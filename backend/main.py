"""
Clave Backend - FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜
ìŠ¤í˜ì¸ì–´-ì˜ì–´ ì½”ë“œìŠ¤ìœ„ì¹­ ê°ì„±ë¶„ì„ API

KSC 2025 ë…¼ë¬¸ ê¸°ë°˜:
- í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ (Role + Few-shot + CoT)
- Self-Consistency (ë‹¤ì¤‘ API í˜¸ì¶œ)
- Gemini 2.5 Flash ì‚¬ìš©
"""

import os
import json
import asyncio
from typing import List, Dict
from dotenv import load_dotenv

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel

import google.generativeai as genai
from google.generativeai.types import HarmCategory, HarmBlockThreshold


# ==================== ì„¤ì • ====================

# í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()

# Gemini API ì„¤ì •
GEMINI_API_KEY = os.getenv("GEMINI_API_KEY", "")
GEMINI_MODEL = os.getenv("GEMINI_MODEL", "gemini-2.5-flash-exp")
TEMPERATURE = float(os.getenv("TEMPERATURE", "0.7"))
MAX_TOKENS = int(os.getenv("MAX_TOKENS", "1024"))
NUM_CALLS = int(os.getenv("NUM_CALLS", "3"))  # Self-consistency í˜¸ì¶œ íšŸìˆ˜

# ì„¤ì • ê²€ì¦
if not GEMINI_API_KEY:
    raise ValueError(
        "GEMINI_API_KEY is not set. "
        "Please set it in .env file or environment variables."
    )

# Gemini ì´ˆê¸°í™”
genai.configure(api_key=GEMINI_API_KEY)
model = genai.GenerativeModel(GEMINI_MODEL)


# ==================== Pydantic ëª¨ë¸ (Request/Response) ====================

class AnalyzeRequest(BaseModel):
    """ê°ì„± ë¶„ì„ ìš”ì²­ ëª¨ë¸"""
    text: str

    class Config:
        json_schema_extra = {
            "example": {
                "text": "Me acostumbre ya a tenerte aqui ğŸ˜¢ Im depressed"
            }
        }


class AnalysisDetail(BaseModel):
    """ë¶„ì„ ì„¸ë¶€ì‚¬í•­"""
    analysis_focus: str
    cultural_context: str
    key_expression: str
    translation: str  # í•œê¸€ ë²ˆì—­


class ConsistencyInfo(BaseModel):
    """Self-consistency ì •ë³´"""
    num_calls: int
    agreement: str
    all_results: list


class AnalyzeResponse(BaseModel):
    """ê°ì„± ë¶„ì„ ì‘ë‹µ ëª¨ë¸"""
    sentiment: str
    confidence: float
    analysis: AnalysisDetail
    consistency_info: ConsistencyInfo


# ==================== í•µì‹¬ ë¡œì§: í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ====================

def build_prompt(text: str) -> str:
    """
    KSC 2025 ë…¼ë¬¸ ê²°ê³¼ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ì •êµí•œ í”„ë¡¬í”„íŠ¸ êµ¬ì„±

    í¬í•¨ ë‚´ìš©:
    - Role Prompting (ì—­í•  ë¶€ì—¬)
    - Few-shot Examples (ë…¼ë¬¸ì˜ ì‹¤ì œ ì˜ˆì‹œ)
    - Chain-of-Thought (ë‹¨ê³„ë³„ ì¶”ë¡ )
    - Cultural context guidelines (ë¬¸í™”ì  ë§¥ë½ ê°€ì´ë“œ)
    """
    prompt = f"""ë‹¹ì‹ ì€ Hispanic-American ì½”ë“œìŠ¤ìœ„ì¹­ ë¬¸í™”ë¥¼ ì „ë¬¸ìœ¼ë¡œ í•˜ëŠ” ê°ì„±ë¶„ì„ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. ì†Œì…œë¯¸ë””ì–´ì—ì„œ ì‚¬ìš©ë˜ëŠ” Spanglishì˜ ë‰˜ì•™ìŠ¤ë¥¼ ì´í•´í•˜ë©°, íŠ¹íˆ ê°•í•œ ê°ì •ì´ ì–¸ì–´ ì „í™˜ì„ í†µí•´ í‘œí˜„ë˜ëŠ” ë¬¸í™”ì  íŒ¨í„´ì„ íŒŒì•…í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

í•µì‹¬ ê°€ì´ë“œë¼ì¸ (ì—°êµ¬ ê²°ê³¼ ê¸°ë°˜):

1. ì½”ë“œìŠ¤ìœ„ì¹­ ì§€ì  ë¶„ì„:
   - ì½”ë“œìŠ¤ìœ„ì¹­ ì§€ì ì´ í•µì‹¬ ê°ì •ì„ ë‹´ê³  ìˆëŠ” ê²½ìš°ê°€ ë§ìŒ
   - ê°•í•œ ê°ì •ì„ í‘œí˜„í•  ë•Œ ë‹¤ë¥¸ ì–¸ì–´ë¡œ ì „í™˜í•˜ëŠ” íŒ¨í„´
   - ì˜ˆ: ìŠ¤í˜ì¸ì–´ ì¤‘ë¦½ì  í…ìŠ¤íŠ¸ + ì˜ì–´ ê°ì • í‘œí˜„ = ì˜ì–´ ë¶€ë¶„ì— ì§‘ì¤‘

2. ë¬¸í™”ì  í‘œí˜„ í•´ì„:
   - JAJAJAJA, jaja = ê¸ì • (ìŠ¤í˜ì¸ì–´ ì›ƒìŒ í‘œí˜„)
   - í•´ì‹œíƒœê·¸ëŠ” Hispanic-American SNSì—ì„œ í•µì‹¬ ê°ì • ì§€í‘œ (ë‹¨ìˆœ ë©”íƒ€ë°ì´í„°ê°€ ì•„ë‹˜)
   - "loco", "cabrÃ³n" = ë§¥ë½ ì˜ì¡´ì  (ì¹œêµ¬ ì‚¬ì´ëŠ” ì¹œê·¼í•¨, ì¼ë°˜ì ìœ¼ë¡œëŠ” ë¶€ì •ì )

3. ê³¼ë„í•œ ë¶„ë¥˜ ë°©ì§€:
   - í‚¤ì›Œë“œ(happy, loco ë“±)ë§Œìœ¼ë¡œ Positive ë¶„ë¥˜í•˜ì§€ ë§ ê²ƒ
   - ì „ì²´ ë§¥ë½ê³¼ ì½”ë“œìŠ¤ìœ„ì¹­ íŒ¨í„´ ê³ ë ¤
   - í‘œë©´ì ìœ¼ë¡œ ì¤‘ë¦½ì ì¸ ìŠ¤í˜ì¸ì–´ + ê°ì •ì  ì˜ì–´ = ì˜ì–´ ë¶€ë¶„ ì‹ ì¤‘íˆ ë¶„ì„

4. ìˆ¨ê²¨ì§„ ê°ì • íƒì§€:
   - ê²‰ë³´ê¸° ì¤‘ë¦½ í…ìŠ¤íŠ¸ + ì´ëª¨í‹°ì½˜ + ì½”ë“œìŠ¤ìœ„ì¹­ = ê°•í•œ ê°ì • ìˆ¨ì–´ìˆëŠ” ê²½ìš° ë§ìŒ
   - ë¶€ì •ì  ê°ì • ê°•ë„ ê³¼ì†Œí‰ê°€í•˜ì§€ ë§ ê²ƒ

Few-shot ì˜ˆì‹œ (KSC 2025 ë…¼ë¬¸):

ì˜ˆì‹œ 1 (ê¸ì •):
ì…ë ¥: "#selfie #goinghome #happy A descansar un poco! #weekend"
ë¶„ì„: í•´ì‹œíƒœê·¸ #happyê°€ ëª…í™•í•œ ê¸ì • í‘œí˜„. "A descansar un poco" (ì¡°ê¸ˆ ì‰¬ëŸ¬ ê°€ì•¼ì§€) + #weekendê°€ ê¸ì •ì  ë§¥ë½ í˜•ì„±. ìŠ¤í˜ì¸ì–´-ì˜ì–´ ì½”ë“œìŠ¤ìœ„ì¹­ì´ ìì—°ìŠ¤ëŸ½ê²Œ ê¸ì •ì  ë¶„ìœ„ê¸° í˜•ì„±.
ì¶œë ¥: {{"sentiment": "positive", "confidence": 0.91, "analysis_focus": "í•´ì‹œíƒœê·¸ #happyê°€ ëª…í™•í•œ ê¸ì • í‘œí˜„ì´ë©° ì£¼ë§ íœ´ì‹ ë§¥ë½ê³¼ ê²°í•©", "cultural_context": "Hispanic-American SNSì—ì„œ í•´ì‹œíƒœê·¸ëŠ” ê°ì • í‘œí˜„ì˜ í•µì‹¬ ìˆ˜ë‹¨", "key_expression": "#happy", "translation": "ì…€ì¹´ ì°ê³  ì§‘ì— ê°€ëŠ” ì¤‘ í–‰ë³µí•´ ì¡°ê¸ˆ ì‰¬ì–´ì•¼ì§€! ì£¼ë§ì´ì•¼"}}

ì˜ˆì‹œ 2 (ë¶€ì • - í•µì‹¬ ë°œê²¬):
ì…ë ¥: "Me acostumbre ya a tenerte aqui ğŸ˜¢ Im depressed y estas lejos"
ë¶„ì„: ìŠ¤í˜ì¸ì–´ ë¶€ë¶„ "Me acostumbre ya a tenerte aqui" (ë„ˆê°€ ì—¬ê¸° ìˆëŠ” ê²Œ ìµìˆ™í•´ì¡Œì–´)ëŠ” í‘œë©´ì ìœ¼ë¡œ ì¤‘ë¦½ì . í•µì‹¬ í¬ì¸íŠ¸: ì§„ì§œ ê°ì •ì€ ì˜ì–´ ì½”ë“œìŠ¤ìœ„ì¹­ "Im depressed"ì—ì„œ í­ë°œ. ì´ëª¨í‹°ì½˜ ğŸ˜¢ + "y estas lejos" (ê·¸ëŸ°ë° ë„Œ ë©€ë¦¬ ìˆì–´)ê°€ ë¶€ì •ì  ê°ì • ê°•í™”.
ì¶œë ¥: {{"sentiment": "negative", "confidence": 0.88, "analysis_focus": "ìŠ¤í˜ì¸ì–´ ë¶€ë¶„ì€ í‘œë©´ì ìœ¼ë¡œ ì¤‘ë¦½ì ì´ë‚˜, ì˜ì–´ ì½”ë“œìŠ¤ìœ„ì¹­ 'Im depressed'ì—ì„œ í•µì‹¬ ê°ì • í‘œí˜„", "cultural_context": "Hispanic-Americanì€ ê°•í•œ ê°ì •ì„ ì–¸ì–´ ì „í™˜ì„ í†µí•´ í‘œí˜„í•˜ëŠ” ë¬¸í™”ì  íŒ¨í„´ - ì½”ë“œìŠ¤ìœ„ì¹­ ì§€ì ì´ ê°ì •ì˜ í´ë¼ì´ë§¥ìŠ¤", "key_expression": "Im depressed", "translation": "ë„ˆê°€ ì—¬ê¸° ìˆëŠ” ê²Œ ìµìˆ™í•´ì¡Œì–´ ğŸ˜¢ ìš°ìš¸í•´ ê·¸ëŸ°ë° ë„Œ ë©€ë¦¬ ìˆì–ì•„"}}

ì˜ˆì‹œ 3 (ì¤‘ë¦½):
ì…ë ¥: "I think I'll buy me a loco burrito. I've never heard of that"
ë¶„ì„: "loco" í‚¤ì›Œë“œê°€ í¬í•¨ë˜ì–´ ìˆì§€ë§Œ ìŒì‹ ì´ë¦„ "loco burrito"ì˜ ì¼ë¶€ì¼ ë¿. ì „ì²´ ë§¥ë½ì€ ë‹¨ìˆœ ì •ë³´ êµí™˜ ëŒ€í™”. ê°ì • í‘œí˜„ì´ ì•„ë‹Œ ì‚¬ì‹¤ ì§„ìˆ .
ì¶œë ¥: {{"sentiment": "neutral", "confidence": 0.82, "analysis_focus": "locoëŠ” ìŒì‹ ì´ë¦„ì˜ ì¼ë¶€ì´ì§€ ê°ì • í‘œí˜„ì´ ì•„ë‹˜. ë§¥ë½ì€ ì •ë³´ ì „ë‹¬ ëª©ì  ëŒ€í™”", "cultural_context": "ë¬¸í™”ì  í‘œí˜„(loco, cabrÃ³n)ì€ ë§¥ë½ì— ë”°ë¼ ì˜ë¯¸ê°€ ì™„ì „íˆ ë‹¬ë¼ì§", "key_expression": "loco burrito", "translation": "ë‚˜ ë¡œì½” ë¶€ë¦¬ë˜ ì‚¬ ë¨¹ì„ ê²ƒ ê°™ì•„. ê·¸ëŸ° ê±° ì²˜ìŒ ë“¤ì–´ë´¤ë„¤"}}

ë¶„ì„ ë‹¨ê³„ (Chain-of-Thought):
1. ìŠ¤í˜ì¸ì–´ì™€ ì˜ì–´ êµ¬ê°„ ì‹ë³„
2. ì½”ë“œìŠ¤ìœ„ì¹­ ì§€ì  ì°¾ê¸°
3. ê° êµ¬ê°„ì˜ ê°ì„± ê°œë³„ ë¶„ì„
4. ë¬¸í™”ì  ë§¥ë½ ê³ ë ¤ (JAJAJAJA = ê¸ì •, í•´ì‹œíƒœê·¸ = ê°ì • ë§ˆì»¤ ë“±)
5. ì–´ëŠ êµ¬ê°„ì´ í•µì‹¬ ê°ì •ì„ ë‹´ê³  ìˆëŠ”ì§€ íŒë‹¨
6. ì‹ ë¢°ë„ ì ìˆ˜ì™€ í•¨ê»˜ ìµœì¢… ê°ì„± ì œê³µ

ë‹¤ìŒ í…ìŠ¤íŠ¸ë¥¼ ë¶„ì„í•˜ì„¸ìš”:
"{text}"

ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œë§Œ ì‘ë‹µí•˜ì„¸ìš” (ë§ˆí¬ë‹¤ìš´, ì½”ë“œë¸”ë¡ ì—†ì´):
{{"sentiment": "positive" | "negative" | "neutral", "confidence": 0.0-1.0, "analysis_focus": "ì–´ë””ì— ì£¼ëª©í–ˆëŠ”ì§€ 1-2ë¬¸ì¥ ìš”ì•½", "cultural_context": "ì™œ ê·¸ë ‡ê²Œ í•´ì„í–ˆëŠ”ì§€ ë¬¸í™”ì  ë°°ê²½", "key_expression": "í•µì‹¬ í‘œí˜„", "translation": "ì…ë ¥ ë¬¸ì¥ì˜ ìì—°ìŠ¤ëŸ¬ìš´ í•œê¸€ ë²ˆì—­"}}"""

    return prompt


# ==================== Gemini API í˜¸ì¶œ ====================

async def analyze_sentiment_single(text: str) -> dict:
    """
    Geminië¥¼ ì‚¬ìš©í•˜ì—¬ ì½”ë“œìŠ¤ìœ„ì¹­ í…ìŠ¤íŠ¸ì˜ ê°ì„± ë¶„ì„ (ë‹¨ì¼ í˜¸ì¶œ)

    Args:
        text: ìŠ¤í˜ì¸ì–´-ì˜ì–´ ì½”ë“œìŠ¤ìœ„ì¹­ ì…ë ¥ í…ìŠ¤íŠ¸

    Returns:
        ê°ì„±, ì‹ ë¢°ë„, ë¶„ì„ ì„¸ë¶€ì‚¬í•­ì„ í¬í•¨í•œ dict
    """
    try:
        prompt = build_prompt(text)

        response = model.generate_content(
            prompt,
            generation_config={
                "temperature": TEMPERATURE,
                "max_output_tokens": MAX_TOKENS,
            },
            safety_settings={
                HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
                HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
            }
        )

        # ë””ë²„ê¹…: response ì „ì²´ êµ¬ì¡° í™•ì¸ (í•„ìš”ì‹œ ì£¼ì„ í•´ì œ)
        # print(f"ğŸ” Response finish_reason: {response.candidates[0].finish_reason if response.candidates else 'No candidates'}")
        # print(f"ğŸ” Safety ratings: {response.candidates[0].safety_ratings if response.candidates else 'No candidates'}")

        # finish_reason=2 (SAFETY) ì²˜ë¦¬
        if response.candidates and response.candidates[0].finish_reason == 2:
            # print(f"âš ï¸  Safety filter triggered. Prompt was:\n{prompt[:200]}...")
            # Safety filter ë¬´ì‹œí•˜ê³  neutral ë°˜í™˜
            return {
                "sentiment": "neutral",
                "confidence": 0.5,
                "analysis_focus": "Safety filter triggered - returning neutral",
                "cultural_context": "Response blocked by safety filter",
                "key_expression": "N/A"
            }

        # JSON ì‘ë‹µ íŒŒì‹±
        result_text = response.text.strip()

        # ë§ˆí¬ë‹¤ìš´ ì½”ë“œë¸”ë¡ ì œê±° (ìˆì„ ê²½ìš°)
        if result_text.startswith("```"):
            result_text = result_text.split("```")[1]
            if result_text.startswith("json"):
                result_text = result_text[4:].strip()

        result = json.loads(result_text)

        # ê²°ê³¼ ê²€ì¦
        if "sentiment" not in result or "confidence" not in result:
            raise ValueError("Geminië¡œë¶€í„° ì˜ëª»ëœ ì‘ë‹µ í˜•ì‹")

        # í•„ë“œëª… í™•ì¸ ë° ê¸°ë³¸ê°’ ì„¤ì •
        if "analysis_focus" not in result:
            result["analysis_focus"] = result.get("process", "")
        if "cultural_context" not in result:
            result["cultural_context"] = result.get("cultural_reason", "")
        if "translation" not in result:
            result["translation"] = "ë²ˆì—­ ì •ë³´ ì—†ìŒ"

        return result

    except json.JSONDecodeError as e:
        # í´ë°±: í…ìŠ¤íŠ¸ì—ì„œ ê°ì„± ì¶”ì¶œ ì‹œë„
        result_text = response.text.lower()
        if "positive" in result_text or "ê¸ì •" in result_text:
            sentiment = "positive"
        elif "negative" in result_text or "ë¶€ì •" in result_text:
            sentiment = "negative"
        else:
            sentiment = "neutral"

        return {
            "sentiment": sentiment,
            "confidence": 0.5,
            "process": "JSON íŒŒì‹± ì‹¤íŒ¨, í´ë°± ì‚¬ìš©",
            "cultural_reason": "N/A",
            "key_expression": "N/A",
            "error": str(e)
        }

    except Exception as e:
        print(f"âŒ Gemini API ì—ëŸ¬: {type(e).__name__}: {str(e)}")  # ë¡œê·¸ ì¶œë ¥
        import traceback
        traceback.print_exc()  # ì „ì²´ ì—ëŸ¬ ìŠ¤íƒ ì¶œë ¥
        raise Exception(f"Gemini API í˜¸ì¶œ ì‹¤íŒ¨: {str(e)}")


# ==================== Self-Consistency ë¡œì§ ====================

def aggregate_results(results: List[Dict]) -> dict:
    """
    ì—¬ëŸ¬ ê°ì„± ë¶„ì„ ê²°ê³¼ ì§‘ê³„

    ë¡œì§:
    1. ê°ì„± ë°œìƒ íšŸìˆ˜ ì¹´ìš´íŠ¸
    2. ë‹¤ìˆ˜(2ê°œ ì´ìƒ ë™ì¼)ê°€ ì¡´ì¬í•˜ë©´ â†’ ë‹¤ìˆ˜ ì‚¬ìš©, ì‹ ë¢°ë„ í‰ê· 
    3. ëª¨ë‘ ë‹¤ë¥´ë©´ â†’ ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ ê²°ê³¼ ì‚¬ìš©
    """
    # ê°ì„± ë°œìƒ íšŸìˆ˜ ì¹´ìš´íŠ¸
    sentiment_counts = {}
    sentiment_confidences = {}

    for result in results:
        sentiment = result["sentiment"]
        confidence = result["confidence"]

        if sentiment not in sentiment_counts:
            sentiment_counts[sentiment] = 0
            sentiment_confidences[sentiment] = []

        sentiment_counts[sentiment] += 1
        sentiment_confidences[sentiment].append(confidence)

    # ë‹¤ìˆ˜ ì°¾ê¸° (2ê°œ ì´ìƒ ê°™ì€ ê°ì„±)
    max_count = max(sentiment_counts.values())

    if max_count >= 2:
        # ë‹¤ìˆ˜ ì¡´ì¬ - ë‹¤ìˆ˜ ì‚¬ìš©
        majority_sentiment = [
            s for s, c in sentiment_counts.items() if c == max_count
        ][0]

        avg_confidence = sum(sentiment_confidences[majority_sentiment]) / len(
            sentiment_confidences[majority_sentiment]
        )

        # ë‹¤ìˆ˜ ê²°ê³¼ ì¤‘ confidenceê°€ ê°€ì¥ ë†’ì€ ê²ƒì—ì„œ ìƒì„¸ ë¶„ì„ ê°€ì ¸ì˜¤ê¸°
        majority_result = max(
            (r for r in results if r["sentiment"] == majority_sentiment),
            key=lambda r: r["confidence"]
        )

        return {
            "sentiment": majority_sentiment,
            "confidence": round(avg_confidence, 2),
            "analysis": {
                "analysis_focus": majority_result.get("analysis_focus", majority_result.get("process", "")),
                "cultural_context": majority_result.get("cultural_context", majority_result.get("cultural_reason", "")),
                "key_expression": majority_result.get("key_expression", ""),
                "translation": majority_result.get("translation", "ë²ˆì—­ ì •ë³´ ì—†ìŒ"),
            },
            "consistency_info": {
                "num_calls": len(results),
                "agreement": f"{max_count}/{len(results)}",
                "all_results": [
                    {
                        "sentiment": r["sentiment"],
                        "confidence": r["confidence"]
                    }
                    for r in results
                ]
            }
        }
    else:
        # ëª¨ë‘ ë‹¤ë¦„ - ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ ì‚¬ìš©
        best_result = max(results, key=lambda r: r["confidence"])

        return {
            "sentiment": best_result["sentiment"],
            "confidence": best_result["confidence"],
            "analysis": {
                "analysis_focus": best_result.get("analysis_focus", best_result.get("process", "")),
                "cultural_context": best_result.get("cultural_context", best_result.get("cultural_reason", "")),
                "key_expression": best_result.get("key_expression", ""),
                "translation": best_result.get("translation", "ë²ˆì—­ ì •ë³´ ì—†ìŒ"),
            },
            "consistency_info": {
                "num_calls": len(results),
                "agreement": f"1/{len(results)} (used highest confidence)",
                "all_results": [
                    {
                        "sentiment": r["sentiment"],
                        "confidence": r["confidence"]
                    }
                    for r in results
                ]
            }
        }


async def analyze_with_consistency(text: str) -> dict:
    """
    ìê¸° ì¼ê´€ì„±ì„ í™œìš©í•œ í…ìŠ¤íŠ¸ ë¶„ì„ (ë‹¤ì¤‘ ë³‘ë ¬ í˜¸ì¶œ)

    ì§‘ê³„ ë¡œì§ (ë…¼ë¬¸ ê¸°ë°˜):
    - 2ê°œ ì´ìƒ ê°™ì€ ê°ì„± â†’ í•´ë‹¹ ê°ì„± ì‚¬ìš©, ì‹ ë¢°ë„ í‰ê· 
    - 3ê°œ ëª¨ë‘ ë‹¤ë¥¸ ê°ì„± â†’ ê°€ì¥ ë†’ì€ ì‹ ë¢°ë„ ì‚¬ìš©

    Args:
        text: ë¶„ì„í•  ì…ë ¥ í…ìŠ¤íŠ¸

    Returns:
        ì§‘ê³„ëœ ê°ì„± ë¶„ì„ ê²°ê³¼ë¥¼ í¬í•¨í•œ dict
    """
    # Gemini APIë¥¼ ë³‘ë ¬ë¡œ ì—¬ëŸ¬ ë²ˆ í˜¸ì¶œ
    tasks = [
        analyze_sentiment_single(text)
        for _ in range(NUM_CALLS)
    ]

    results = await asyncio.gather(*tasks, return_exceptions=True)

    # ì˜ˆì™¸ í•„í„°ë§
    valid_results = [
        r for r in results
        if not isinstance(r, Exception) and "sentiment" in r
    ]

    if not valid_results:
        raise Exception("ëª¨ë“  API í˜¸ì¶œ ì‹¤íŒ¨")

    # ê²°ê³¼ ì§‘ê³„
    return aggregate_results(valid_results)


# ==================== FastAPI ì• í”Œë¦¬ì¼€ì´ì…˜ ====================

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(
    title="Clave API",
    description="Spanish-English Code-switching Sentiment Analysis API",
    version="1.0.0",
)

# CORS ì„¤ì • (Android ì•± í†µì‹ ìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ê°œë°œìš©: ëª¨ë“  origin í—ˆìš©
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)


# ==================== API ì—”ë“œí¬ì¸íŠ¸ ====================

@app.get("/")
async def root():
    """ë£¨íŠ¸ ì—”ë“œí¬ì¸íŠ¸ - ì„œë²„ ìƒíƒœ í™•ì¸"""
    return {
        "message": "Clave API is running",
        "version": "1.0.0",
        "status": "healthy",
        "model": GEMINI_MODEL,
        "endpoints": {
            "analyze": "POST /api/analyze",
            "health": "GET /api/health"
        }
    }


@app.post("/api/analyze", response_model=AnalyzeResponse)
async def analyze_sentiment_endpoint(request: AnalyzeRequest):
    """
    ìŠ¤í˜ì¸ì–´-ì˜ì–´ ì½”ë“œìŠ¤ìœ„ì¹­ í…ìŠ¤íŠ¸ì˜ ê°ì„± ë¶„ì„

    **KSC 2025 ë…¼ë¬¸ ê¸°ë°˜ í”„ë¡¬í”„íŠ¸ ì—”ì§€ë‹ˆì–´ë§ ì‚¬ìš©:**
    - Role Prompting (Hispanic-American ì „ë¬¸ê°€)
    - Few-shot Learning (ë…¼ë¬¸ì˜ ì‹¤ì œ ì˜ˆì‹œ)
    - Chain-of-Thought (ë‹¨ê³„ë³„ ë¶„ì„)
    - Self-Consistency (3íšŒ ë³‘ë ¬ í˜¸ì¶œ)

    **Parameters:**
    - text: ë¶„ì„í•  ìŠ¤í˜ì¸ì–´-ì˜ì–´ ì½”ë“œìŠ¤ìœ„ì¹­ í…ìŠ¤íŠ¸

    **Returns:**
    - sentiment: "positive" | "negative" | "neutral"
    - confidence: 0.0 ~ 1.0 (ì‹ ë¢°ë„)
    - analysis: ë¶„ì„ ê³¼ì •, ë¬¸í™”ì  ì´ìœ , í•µì‹¬ í‘œí˜„
    - consistency_info: Self-consistency ê²°ê³¼ ìƒì„¸
    """

    # ì…ë ¥ ê²€ì¦
    if not request.text or not request.text.strip():
        raise HTTPException(
            status_code=400,
            detail="í…ìŠ¤íŠ¸ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤. 'text' í•„ë“œë¥¼ ì œê³µí•´ì£¼ì„¸ìš”."
        )

    if len(request.text) > 1000:
        raise HTTPException(
            status_code=400,
            detail="í…ìŠ¤íŠ¸ê°€ ë„ˆë¬´ ê¹ë‹ˆë‹¤ (ìµœëŒ€ 1000ì)."
        )

    try:
        # Self-consistencyë¥¼ ì‚¬ìš©í•œ ê°ì„± ë¶„ì„
        result = await analyze_with_consistency(request.text)
        return result

    except Exception as e:
        raise HTTPException(
            status_code=500,
            detail=f"ê°ì„± ë¶„ì„ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {str(e)}"
        )


@app.get("/api/health")
async def health_check():
    """API ìƒíƒœ í™•ì¸ ì—”ë“œí¬ì¸íŠ¸"""
    return {
        "status": "healthy",
        "service": "Clave Sentiment Analysis API",
        "model": GEMINI_MODEL,
        "num_calls": NUM_CALLS
    }


# ==================== ì„œë²„ ì‹œì‘ ì´ë²¤íŠ¸ ====================

@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ ì‹¤í–‰"""
    print("=" * 60)
    print("ğŸ”‘ Clave API Server Starting...")
    print(f"ğŸ“ Model: {GEMINI_MODEL}")
    print(f"ğŸ”„ Self-consistency calls: {NUM_CALLS}")
    print(f"ğŸŒ¡ï¸  Temperature: {TEMPERATURE}")
    print("=" * 60)
